_target_: src.models.multistage_text_motion_model.MultistageTextMotionModel
generator:
  _target_: src.models.networks.discrete_diffusion.DiscreteDiffusion

autoencoder:
  _target_: src.models.networks.videogpt_vq_vae.VQVAE
  checkpoint_path: __None__
  embedding_dim: 128
  n_codes: 2048
  n_hiddens: 256
  n_res_layers: 2
  downsample: [2, 8, 8]
  sequence_length: ${datamodule.sequence_length}
  resolution: ${datamodule.resolution}

generator_losses:
  _target_: src.models.metrics.loss.ComputeLosses
  mode: __None__
  loss_dict:
    l_dummy: 1.0

#autoencoder_losses:
#  _target_: src.models.metrics.loss.ComputeLosses
#  mode: smpl
#  loss_dict:
#    l_dummy: 1.0

freeze_models_dict:
  generator: []
  autoencoder: [encoder, decoder, pre_vq_conv, post_vq_conv, codebook]
  length_estimator: []

checkpoint_paths:
  autoencoder: /home1/chemburk/pretrained/vqvae_checkpoint.ckpt

lr_args:
  gen_lr: 1e-4
  auto_lr: 0.000001
  len_est_lr: 0

collate_fn: ${datamodule.collate_fn}

do_evaluation: true

devices: ${trainer.devices}

defaults:
  - /model/textencoder/clip_text_embedding@generator.textencoder
  - /model/motionencoder/diffusion_transformer@generator.diffusion_model
  - /model/evaluator@evaluator
