task_name: train
tags:
- dev
train: true
test: true
ckpt_path: null
eval_ckpt: /home/ICT2000/achemburkar/Desktop/repos/text-to-motion/checkpoints/kit/text_mot_match/model/finest.tar
batch_size: 16
seed: null
datamodule:
  transforms:
    rots2rfeats:
      name: SMPLVelP
      _target_: src.datamodules.datasets.transforms.rots2rfeats.SMPLVelP
      pose_rep: rot6d
      path: ${paths.deps}/transforms/rots2rfeats/smplvelp/${.pose_rep}/${datamodule.dataname}
      canonicalize: true
      normalization: ${datamodule.transforms.normalization}
    rots2joints:
      name: SMPLH
      _target_: src.datamodules.datasets.transforms.rots2joints.SMPLH
      jointstype: mmm
      input_pose_rep: matrix
      path: ${paths.smpl_path}
      batch_size: 256
      gender: neutral
    joints2jfeats:
      name: Rifke
      _target_: src.datamodules.datasets.transforms.joints2jfeats.Rifke
      path: ${paths.deps}/transforms/joints2jfeats/rifke/${datamodule.dataname}
      normalization: ${datamodule.transforms.normalization}
      forward_filter: false
    name: HumanMLSMPLTransform
    ename: smpl
    _target_: src.datamodules.datasets.transforms.HumanMLSMPLTransform
    normalization: false
    joints_num: ${datamodule.joints_num}
  sampler:
    _target_: src.datamodules.datasets.sampling.FrameSampler
    request_frames: 40
    threshold_reject: 0.75
    sampling: conseq
    sampling_step: 1
    max_len: 10000
    min_len: 10
  dataname: kit-ml
  _target_: src.datamodules.humanml_datamodule.HumanMLDataModule
  datapath: ${paths.datasets}/Guo-KIT-ML/KIT-ML
  splitpath: ${paths.datasets}/Guo-KIT-ML/KIT-ML
  batch_size: ${batch_size}
  num_workers: 0
  framerate: 12.5
  joints_num: 21
  dim_pose: 251
  max_motion_length: 196
  feat_bias: 20
  tiny: false
  progress_bar: true
  collate_fn: ${model.collate_fn}
  deps: ${paths.deps}
  devices: ${trainer.devices}
model:
  generator:
    vae_model:
      _target_: src.models.motionencoder.mld_vae.MldVae
      arch: encoder_decoder
      ff_size: 1024
      num_layers: 9
      num_heads: 4
      dropout: 0.1
      normalize_before: false
      activation: gelu
      position_embedding: learned
      latent_dim:
      - 1
      - 256
      ablation:
        MLP_DIST: false
        SKIP_CONNECT: true
        PE_TYPE: mld
        DIFF_PE_TYPE: mld
    _target_: src.models.networks.mld_vae_net.MLDVae
    transforms: ${datamodule.transforms}
    vae: true
    loss_param_dict:
      stage: vae
  evaluator:
    motionencoder:
      textencoder:
        _target_: src.models.text_models.text_encoder_bi_gru_co.TextEncoderBiGRUCo
        hidden_size: 512
        word_size: 300
        pos_size: 15
        output_size: 512
      motion_encoder:
        _target_: src.models.motionencoder.motion_encoder_bi_gru_co.MotionEncoderBiGRUCo
        input_size: 512
        hidden_size: 1024
        output_size: 512
      _target_: src.models.networks.guo_text_motion_matching.GuoTextMotionMatching
      transforms: ${datamodule.transforms}
      vae: true
    autoencoder:
      motionencoder:
        name: conv_motion_snip_encoder
        _target_: src.models.motionencoder.conv_motion_snip_encoder.ConvMotionSnipEncoder
        latent_size: 512
        vae: true
        hidden_size: 512
        droupout: 0.2
        activation: LeakyReLU
      motiondecoder:
        name: conv_snip_motion_decoder
        _target_: src.models.motiondecoder.conv_snip_motion_decoder.ConvSnipMotionDecoder
        latent_size: 512
        vae: true
        hidden_size: 384
        droupout: 0.2
        activation: LeakyReLU
      _target_: src.models.networks.guo_autoencoder.GuoAutoEncoder
      transforms: ${datamodule.transforms}
      vae: true
      autoencoder_hidden_size: 384
      autoencoder_latent_size: 512
      droupout: 0.2
      activation: LeakyReLU
    _target_: src.utils.evaluator.Evaluator
    checkpoint_paths: ${eval_ckpt}
    diversity_times: 30
  _target_: src.models.text_motion_model.TextMotionModel
  losses:
    _target_: src.models.metrics.loss.ComputeLosses
    mode: smpl
    loss_dict:
      l_mldrecfeats: 1.0
      l_mldrecjoints: 1.0
      l_mldkl: 0.0001
    loss_opts:
      loss_feat_type: rfeats
  collate_fn: collate_datastruct_and_text
  checkpoint_paths: ''
  do_evaluation: true
  lr_args:
    gen_lr: 1.0e-08
callbacks:
  model_checkpoint:
    _target_: pytorch_lightning.callbacks.ModelCheckpoint
    dirpath: ${paths.output_dir}/checkpoints
    filename: epoch_{epoch:03d}
    monitor: total/val
    verbose: false
    save_last: true
    save_top_k: 1
    mode: min
    auto_insert_metric_name: false
    save_weights_only: false
    every_n_train_steps: null
    train_time_interval: null
    every_n_epochs: null
    save_on_train_epoch_end: null
  fid_checkpoint:
    _target_: pytorch_lightning.callbacks.ModelCheckpoint
    dirpath: ${paths.output_dir}/checkpoints
    filename: fid_best
    monitor: Metrics/fid-val
    verbose: false
    save_last: true
    save_top_k: 1
    mode: min
    auto_insert_metric_name: true
    save_weights_only: false
    every_n_train_steps: null
    train_time_interval: null
    every_n_epochs: null
    save_on_train_epoch_end: null
  precision_checkpoint:
    _target_: pytorch_lightning.callbacks.ModelCheckpoint
    dirpath: ${paths.output_dir}/checkpoints
    filename: precision_best
    monitor: Metrics/R-precision-Top-3-val
    verbose: false
    save_last: true
    save_top_k: 1
    mode: max
    auto_insert_metric_name: false
    save_weights_only: false
    every_n_train_steps: null
    train_time_interval: null
    every_n_epochs: null
    save_on_train_epoch_end: null
  early_stopping:
    _target_: pytorch_lightning.callbacks.EarlyStopping
    monitor: total/val
    min_delta: 0.0
    patience: 5000
    verbose: false
    mode: max
    strict: true
    check_finite: true
    stopping_threshold: null
    divergence_threshold: null
    check_on_train_epoch_end: null
  model_summary:
    _target_: pytorch_lightning.callbacks.RichModelSummary
    max_depth: -1
trainer:
  _target_: pytorch_lightning.Trainer
  default_root_dir: ${paths.output_dir}
  min_epochs: 1
  max_epochs: 500
  accelerator: ddp
  gpus: 2
  devices:
  - 1
  deterministic: false
paths:
  root_dir: ${oc.env:PROJECT_ROOT}
  log_dir: ${paths.root_dir}/logs/
  output_dir: ${hydra:runtime.output_dir}
  work_dir: ${hydra:runtime.cwd}
  datasets: /data/feng/Gestures
  deps: ${paths.datasets}/Deps/TextMotionDeps
  smpl_path: ${paths.datasets}/SMPL_Data/models/smplh
extras:
  ignore_warnings: false
  enforce_tags: true
  print_config: true
